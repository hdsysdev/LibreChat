services:
 
  # -------------------------------------------------------------------
  # 1) The Speeches TTS server
  # -------------------------------------------------------------------
  speeches:
    image: ghcr.io/speaches-ai/speaches:latest-cpu   # replace with the correct Speeches image if yours is different
    container_name: speeches
    restart: unless-stopped  
    ports:
      - "8000:8000"                            # Speeches serves on 8000/v1/audio/speech
    environment:
      # So that huggingface-cli can pull private models if needed:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-""}
      # Fixed revision for the Kokoro ONNX release
      - KOKORO_REVISION=c97b7bbc3e60f447383c79b2f94fee861ff156ac
      # Optional: turn off auth if your librechat instance is public
      - SPEECHES_NO_AUTH=1
      - LOG_LEVEL=debug
    volumes:
      # persist downloaded models so you don't re-download every time
      - tts-hf-cache:/root/.cache/huggingface/hub
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://0.0.0.0:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    entrypoint: >
      /bin/bash -eux -c "
        # 1) Download Kokoro ONNX model (346MB) + voices.bin (5.5MB)
        huggingface-cli download hexgrad/Kokoro-82M \
          --include 'kokoro-v0_19.onnx' \
          --revision $KOKORO_REVISION &&

        mkdir -p /root/.cache/huggingface/hub/models--hexgrad--Kokoro-82M/snapshots/$KOKORO_REVISION && 
        curl -L \
          https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files/voices.bin \
          -o /root/.cache/huggingface/hub/models--hexgrad--Kokoro-82M/snapshots/$KOKORO_REVISION/voices.bin &&

        # 2) Download all Piper voices (~7.7GB).  If you only want English, swap this for the --include examples
        huggingface-cli download rhasspy/piper-voices &&

        # 3) Launch the Speeches FastAPI app
        uvicorn main:app --host 0.0.0.0 --port 8000
      "
  api:
    # build:
    #   context: .
    #   dockerfile: Dockerfile.multi
    #   target: api-build
    image: ghcr.io/danny-avila/librechat-dev-api:latest
    container_name: LibreChat-API
    ports:
      - 3080:3080
    depends_on:
      - mongodb
      - rag_api
      - speeches
    restart: always
    extra_hosts:
    - "host.docker.internal:host-gateway"
    env_file:
      - .env
    environment:
      - HOST=0.0.0.0
      - NODE_ENV=production
      - MONGO_URI=mongodb://mongodb:27017/LibreChat
      - MEILI_HOST=http://meilisearch:7700
      - RAG_PORT=${RAG_PORT:-8000}
      - RAG_API_URL=http://rag_api:${RAG_PORT:-8000}
    volumes:
      - type: bind
        source: ./librechat.yaml
        target: /app/librechat.yaml
      - ./images:/app/client/public/images
      - ./uploads:/app/uploads
      - ./logs:/app/api/logs

  client:
    image: nginx:1.27.0-alpine
    container_name: LibreChat-NGINX
    ports:
      - 80:80
      - 443:443
    depends_on:
      - api
    restart: always
    volumes:
      - ./client/nginx.conf:/etc/nginx/conf.d/default.conf
      - /etc/letsencrypt/live/slopchat.hddev.tech:/etc/letsencrypt/live/slopchat.hddev.tech
      - /etc/letsencrypt/archive/slopchat.hddev.tech:/etc/letsencrypt/archive/slopchat.hddev.tech
      - /etc/letsencrypt/options-ssl-nginx.conf:/etc/letsencrypt/options-ssl-nginx.conf
      - /etc/letsencrypt/ssl-dhparams.pem:/etc/letsencrypt/ssl-dhparams.pem
  mongodb:
    container_name: chat-mongodb
    # ports:  # Uncomment this to access mongodb from outside docker, not safe in deployment
    #   - 27018:27017
    image: mongo
    restart: always
    volumes:
      - ./data-node:/data/db
    command: mongod --noauth
  meilisearch:
    container_name: chat-meilisearch
    image: getmeili/meilisearch:v1.12.3
    restart: always
    # ports: # Uncomment this to access meilisearch from outside docker
    #   - 7700:7700 # if exposing these ports, make sure your master key is not the default value
    env_file:
      - .env
    environment:
      - MEILI_HOST=http://meilisearch:7700
      - MEILI_NO_ANALYTICS=true
    volumes:
      - ./meili_data_v1.12:/meili_data
  vectordb:
    image: ankane/pgvector:latest
    environment:
      POSTGRES_DB: mydatabase
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
    restart: always
    volumes:
      - pgdata2:/var/lib/postgresql/data
  rag_api:
    image: ghcr.io/danny-avila/librechat-rag-api-dev-lite:latest
    environment:
      - DB_HOST=vectordb
      - RAG_PORT=${RAG_PORT:-8000}
    restart: always
    depends_on:
      - vectordb
    env_file:
      - .env

volumes:
  pgdata2:
  tts-hf-cache: